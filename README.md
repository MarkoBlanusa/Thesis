<!-----â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“>
## ğŸ¯ Goal

End-to-end research code for my Masterâ€™s thesis on **cryptocurrency
portfolio optimisation**.  
The repo covers **data ingestion â†’ dataset engineering â†’ benchmark
models â†’ RL (PPO) trading agent â†’ result notebooks** so that anyone can
re-run experiments or plug in new assets with minimal effort.

Thesis/
â”‚
â”œâ”€â”€ Project_code/                 â† all Python / notebook code
â”‚   â”œâ”€â”€ data/                     â† ready-made datasets (CSV + HDF5)
â”‚   â”œâ”€â”€ data_retrievers/          â† scripts/notebooks that build `data/`
â”‚   â”‚   â”œâ”€â”€ binance.py
â”‚   â”‚   â”œâ”€â”€ data_collector.py
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ main_data.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”œâ”€â”€ lunarcrush_retriever.ipynb
â”‚   â”‚   â””â”€â”€ data_retriever.ipynb
â”‚   â”œâ”€â”€ PPO_dataset_maker.py      â† turn raw OHLCV into PPO sequences
â”‚   â”œâ”€â”€ garch_adcc_model.ipynb
â”‚   â”œâ”€â”€ lstm_models.ipynb
â”‚   â”œâ”€â”€ xgb_adcc_model.ipynb
â”‚   â”œâ”€â”€ main_ray_portfolio.py
â”‚   â”œâ”€â”€ trade_env_ray_portfolio.py
â”‚   â”œâ”€â”€ main_test_ray_portfolio.py
â”‚   â””â”€â”€ test_trade_env_ray_portfolio.py
â”‚
â”œâ”€â”€ Results_final/                â† published metrics, plots, weights
â”œâ”€â”€ Studies/                      â† academic papers that motivated work
â”œâ”€â”€ requirements.txt / environment.yml
â””â”€â”€ README.md                     â† **you are here**


ğŸš€ Quick start
git clone https://github.com/MarkoBlanusa/Thesis.git
cd Thesis
git lfs pull                       # download ~4.7 GB of datasets

python -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt


ğŸ› ï¸ Data layer
Script / Notebook	Purpose	Output
main_data.py	Streams OHLCV candles from Binance and stores them in HDF5	data/binance.h5
PPO_dataset_maker.py	Windows & normalises data for PPO	data/*.npy
lunarcrush_retriever.ipynb	Social-sentiment via LunarCrush API	data/lunarcrush_features.csv
data_retriever.ipynb	Macro data from Yahoo + crypto subset	data/macro_crypto_features.csv

Tip: retrievers take CLI flags or notebook widgets so you can add symbols or adjust dates in seconds.

.

ğŸ“Š Benchmark models
garch_adcc_model.ipynb â€“ GJR-GARCH-ADCC baseline

lstm_models.ipynb â€“ two multivariate LSTM variants

xgb_adcc_model.ipynb â€“ gradient-boosted covariance model

Each notebook ingests the same CSV/HDF5 datasets and logs metrics to Results_final/.

ğŸ¤– Reinforcement Learning (PPO)
File	Role
main_ray_portfolio.py	Launches RLlib PPO training with YAML config
trade_env_ray_portfolio.py	Custom Gym env: multi-asset weights, fees
*_test_*.py	Verbose test harness with extra prints

Where do the RLlib/Tune results go?
By default, Ray writes every experiment to ~/ray_results/<trainable>/<timestamp>/â€¦ on the userâ€™s home drive 
docs.ray.io
stackoverflow.com
.
Youâ€™ll find checkpoints (checkpoint_*), progress CSVs, and TensorBoard event files there. Start TensorBoard with:

bash
Copier
Modifier
tensorboard --logdir ~/ray_results
You can change the location by:

Passing local_dir="path/to/runs" to tune.Tuner / tune.run 
stackoverflow.com
; or

Setting storage_path via ray.air.RunConfig (Ray â‰¥2.3) 
discuss.ray.io
github.com
.

If you forget to set these, Ray may duplicate large folders in both the custom path and ~/ray_results (known issue)

ğŸ“ˆ Results & reproducibility
All final plots, tables, and trained checkpoints that appear in the thesis live under Results_final/.
Delete the folder and rerun the pipelines to reproduce from scratch.

ğŸ“ Extending the project
New assets â€“ add symbol to data_retriever.ipynb; regenerate CSV.

Different API â€“ subclass a new client in data_retrievers/; call from main_data.py.

New RL algorithm â€“ swap RLlib trainer in main_ray_portfolio.py; env stays unchanged.

âš™ï¸ Troubleshooting
Issue	Fix
Push rejected > 2 GiB	Ensure file type is in .gitattributes so Git LFS handles it.
Ray fills home drive	Pass local_dir/storage_path or clean ~/ray_results periodically.
CUDA OOM	Lower train_batch_size in PPO YAML or run CPU-only.

ğŸ“š References
Annotated PDFs of the key academic papers are stored in Studies/.
